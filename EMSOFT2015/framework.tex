\section{Framework}
\label{framework}

\subsection{Decomposing a mission into scenarios and agents}
To motivate our thinking about the problem of safe autonomous navigation, we consider the problem of driving between two designated points, for example the cities of New York and Philadelphia in the U.S.
On such a trip, the autonomous car will face a number of situations, or \emph{scenarios}, which it must know how to recognize, enter, negotiate, and exit in a safe and timely manner.
For example, the car will encounter roundabouts, 
traffic lights and four-way intersections, 
on-ramps to highways and merging lanes, 
slower cars that must be passed, 
lane changes, 
off-ramps, 
pedestrians at designated and non-designated crossing points, 
stop-and-go traffic, 
and various traffic signals like speed limits, school zones, etc.
We therefore think of a driving mission as an ordered sequence of scenarios.
The exact sequence that will be encountered is not know ahead of time. 
For example, it is not known whether the car will encounter slow traffic on the road, or whether some road has a large pothole that must be avoided.
Moreover, it is clear that some scenarios, like traffic lights, will be encountered more than once, albeit with minor site-specific differences. 
The key observation however is that the diversity of scenarios is, to a first order of approximation, finite. 
That is, there is a recognizable, finite set of scenario types that is sufficient to describe most autonomous navigation missions.

Formally, let $\Sc = \{s_0,s_1,\ldots,s_{N-1}\}$ be a set of scenarios. 
E.g., $s_0 = $ Roundabout, $s_1 = $Lane change, $s_2 = $ PassOnTheLeft, etc. 
(Each of these scenario types will be itself formalized in what follows).
Then a mission $M$ is a finite string on $\Sc$, $M \in \Sc^*$.
Note that each such scenario may have multiple realizations (e.g. a roundabout with 3 vehicles in it, a roundabout with 1 vehicle, etc.), so in what follows we will distinguish between scenario types (elements of $\scenarioSet$) and scenario \emph{instances} which can be thought of as instantiations of scenario types.
When we speak of just a scenario, we mean a scenario instance.

Therefore, if we can verify the safety of the autonomous sytem's behavior in each scenario,
and compose the scenarios in a safe manner, 
then we have verified that the mission is safe.

Within each scenario, we can recognize a recurring set of entities: 
the autonomous vehicle whose operation we seek to verify (a.k.a. the \emph{ego} vehicle), the other vehicles on the road, pedestrians, traffic signage, and the road network itself. 
We will refer to these as \emph{agents}: an agent is ``a person or thing that causes something to happen'' according to the Merriam-Webster dictionary.
We can make this more precise and further specify that an agent is an entity that functions continuously and autonomously in the environment, and whose presence can be sensed by other agents. 
It might seem odd at first blush to think of the road network or the traffic signage as agents, but note that we do not require an agent to be animate.
The road and signage are inanimate agents, that do function autonomously and continuously in any given scenario, and their presence can indeed be sensed by the animate agents (cars and vehicles).
Moreover, note for example that some traffic lights will adjust their cycles depending on how many cars are passing them, or that travel direction in a lane can change depending on the direction of heaviest traffic.
Thus this is a case of an inanimate agent sensing and reacting to other agents in the environment.
As the traffic in major cities becomes more connected and more adaptive, we can expect such cases to increase in number. 
Formally, we recognize the following set of four agent \emph{types}
\[\agentTypeSet = \{\texttt{vehicle, pedestrian, road, trafficSignage}\}\]
Each agent type can have many (parametrized) instances, e.g. $\texttt{trafficSignage}$ can have instances speedLimit(70mph), speedLimit(25mph), HOVLane(3pm-6pm), or noPassingZone.
Note that the $\texttt{vehicle}$ agent type can have instances that are autonomous vehicles, and other instances that are human-driven (and therefore that have different behaviors from the ego vehicle, which is by definition autonomous). 
We denote the set of instances of agents in $\agentTypeSet$ by $I(\agentTypeSet)$.
Clearly, $I(\agentTypeSet)$ is infinite.
When we just speak of an agent, we mean an agent instance.

In addition to the sensible traffic signage, the car must observe the imperceptible laws of the road, i.e., laws that don't have a physical manifestation. 
For example, one such law says that on the highway, a faster car must always pass on the left of a slower car that's in front of it.
Another law says that a car must not be so slow so as to impede traffic flow. 
These laws constitute constraints on the car's behavior in some or all of the above scenarios.

Formally, we define a scenario instance to be a tuple $(T, \agentInstanceSet,\behavior)$ where
\begin{itemize}
\item $T \in \preals$ is a time horizon on the scenario.
%
\item $A$ is a collection of agent \emph{instances} from the set $I(\agentTypeSet)$.
E.g an instance of scenario $s_0$ (Roundabout) might have the agents 
\begin{eqnarray*}
\agentInstanceSet = \{&egoVehicle, otherVehicle1, rndAbt(3), \\ 
& speedLimit(25mph)\} \subset I(\agentTypeSet)
\end{eqnarray*}
where $egoVehicle$ and $otherVehicle1$ are instances of type $\texttt{vehicle}$, 
$rndAbout(n)$ is an instance of $\texttt{road}$ indicating a round-about with $n$ entry points (which are also exit points),
and $speedLimit(Vmph)$ is an intance of $\texttt{trafficSignage}$ indicating a speed limit sign that reads $V$ mph.
Another scenario instance has the agents
\begin{eqnarray*}
\agentInstanceSet = \{&EgoVehicle, OtherVehicle1, rndAbt(2), \\ 
& speedLimit(35mph)\} \subset I(\agentTypeSet)
\end{eqnarray*}
The set $\agentInstanceSet$ always includes the ego vehicle, i.e., the system whose safe behavior we want to verify.
%
\item $\behavior = \{\behavior_a \sut a \in \agentInstanceSet \setminus egoVehicle\}$ is a bounded-time behavior description for each of the agent instances in $\agentInstanceSet$.
\end{itemize}

Describing the behavior $\behavior_a$ of an agent instance requires us to formally describe an agent. We do so in the next section using hierarcical communicating hybrid automata.

\subsection{What is safety?}
\label{safety}
Absolute safety imperative -> more detailed behavior constraints that guarantee safety int eh scenario.

\subsection{Hierarchical communicating hybrid \\automata}
\label{HCHA}
Because autonomous systems are physical systems controlled by software, hybrid automata (HA) are a suitable formalism for modeling them.
Because the complexity of autonomous systems is significant, they are typically designed at multiple levels of abstraction, 
with different teams handling the design at different levels.
E.g. the mapping team might design the algorithm for finding the waypoints along a shortest route from start to end.
For this design, knowledge about, say, the powertrain control of the car is immaterial and abstracted away.
Indeed, details about the road itself are abstracted away as well.
Instead, it is represented as a directed graph.

The resulting system's description is given at multiple levels of abstraction (or multiple levels of detail). 
To model this situation, we adopt \emph{hierarchical} HA: each mode of the HA is itself an HA, down to some level.

Finally because these HHA, each representing an agent, are sensed by other agents in the scenario, we must model this sensing. 
We do so via the inputs to each HHA: given agent instance $a$, every other agent is associated with an input port on $a$.
When that other agent is within sensing distance of $a$, that input port is occupied by that agent's sensed information.


\todo[inline]{Refer to Charon}
